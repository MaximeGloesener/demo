{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fXzthfb3fVHL"
      },
      "outputs": [],
      "source": [
        "# Function to copy files\n",
        "def copy_files(files, split, image_dir, label_dir):\n",
        "    print('Copying files to', os.path.join(split))\n",
        "    for file in tqdm(files):\n",
        "        shutil.copy(os.path.join(image_dir, file + '.jpg'), os.path.join(split, 'images'))\n",
        "        shutil.copy(os.path.join(label_dir, file + '.txt'), os.path.join(split, 'labels'))\n",
        "\n",
        "def create_splits(image_dir, label_dir, train_pct, val_pct, max_samples=None):\n",
        "    # Make sure the percentages add up to 100\n",
        "    assert train_pct + val_pct <= 1.0, \"Train and validation percentages should sum up to 1.0 or less\"\n",
        "\n",
        "    # Create directories for the splits if they don't exist\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for sub_dir in ['images', 'labels']:\n",
        "            os.makedirs(os.path.join(split, sub_dir), exist_ok=True)\n",
        "\n",
        "    # Gather all file names (without extensions)\n",
        "    file_names = [os.path.splitext(file)[0] for file in os.listdir(image_dir)]\n",
        "\n",
        "    # Shuffle the file names\n",
        "    random.shuffle(file_names)\n",
        "\n",
        "    # If max_samples is set, truncate the list\n",
        "    if max_samples is not None:\n",
        "        file_names = file_names[:max_samples]\n",
        "\n",
        "    # Calculate split sizes\n",
        "    total_files = len(file_names)\n",
        "    train_size = int(total_files * train_pct)\n",
        "    val_size = int(total_files * val_pct)\n",
        "\n",
        "    # Split the file names\n",
        "    train_files = file_names[:train_size]\n",
        "    val_files = file_names[train_size:train_size + val_size]\n",
        "    test_files = file_names[train_size + val_size:]\n",
        "\n",
        "\n",
        "    # Copy files to respective directories\n",
        "    copy_files(train_files, 'train', image_dir, label_dir)\n",
        "    copy_files(val_files, 'val', image_dir, label_dir)\n",
        "    copy_files(test_files, 'test', image_dir, label_dir)\n",
        "\n",
        "    print(f\"\\nDataset split complete: {len(train_files)} train, {len(val_files)} val, {len(test_files)} test samples.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1f8o5hbfVtK",
        "outputId": "4a4387b3-4d66-420a-eb66-568435d19445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying files to train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 700/700 [09:19<00:00,  1.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying files to val\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [02:38<00:00,  1.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying files to test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:19<00:00,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset split complete: 700 train, 200 val, 100 test samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the dataset for the correct task (segmentation or detection)\n",
        "#task = \"segmentation\"\n",
        "task = \"detection\"\n",
        "create_splits('images', task, train_pct=0.7, val_pct=0.2, max_samples=1000) # dataset contains 23 000 images, you can set a max samples and set the % split per train/val/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xpaF0qCgHDM"
      },
      "outputs": [],
      "source": [
        "# load a pretrained COCO model and fine tune it (recommended for training)\n",
        "model = YOLO('yolov8n.pt') # Detection\n",
        "#model = YOLO('yolov8n-seg.pt') # Segmentation\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data='./data.yaml', epochs=20, imgsz=640)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
